{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yaml import safe_load\n",
    "setting = safe_load(open(\"setting.yml\"))\n",
    "# https://medium.com/@ruslanmv/generative-ai-for-text-generation-from-scratch-25db8d6cd335\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer , AutoModelForCausalLM \n",
    "\n",
    "# fine-tune a model with LoRA, only the LoRA weights are stored for efficiency. \n",
    "# Therefore, you need to first load the original model, then the LoRA weights in a second step.\n",
    "base_model = AutoModelForCausalLM.from_pretrained(setting['model']['name'],token=setting['api_tokens']['huggingface']).to('cuda')\n",
    "tokenizer = AutoTokenizer.from_pretrained(setting['model']['name'],token=setting['api_tokens']['huggingface'])\n",
    "\n",
    "prompt = \"What is Descript of Extra Window Memory Injection?\"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to('cuda')\n",
    "output1 = base_model.generate(input_ids,max_length =250)\n",
    "generated_text = tokenizer.decode(output1[0], skip_special_tokens=True)\n",
    "print(\"Base:\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_model = AutoModelForCausalLM.from_pretrained(setting['model']['finetune_model'],token=setting['api_tokens']['huggingface']).to('cuda')\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to('cuda')\n",
    "output2 = finetune_model.generate(input_ids,max_length =250)\n",
    "generated_text = tokenizer.decode(output2[0], skip_special_tokens=True)\n",
    "print(\"Finetune:\")\n",
    "print(generated_text)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
